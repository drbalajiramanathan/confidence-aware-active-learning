<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Model Test</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
</head>
<body>
   <h1>TF.js Model Loader</h1>
   <input type="file" id="imageUpload" accept="image/*">
<br>
   <img id="uploadedImage" alt="Upload preview" style="width: 224px; height: 224px; margin-top: 10px; border: 1px solid #ccc; display: none;">
<br>
<button id="predictButton" style="margin-top: 10px; font-size: 16px;">Predict</button>
<p id="result" style="font-weight: bold; font-size: 18px; margin-top: 10px;">Result:</p>
    <p id="status">Loading model...</p>

 <script>
    // --- HTML Elements ---
    const status = document.getElementById('status');
    const imageUpload = document.getElementById('imageUpload');
    const uploadedImage = document.getElementById('uploadedImage');
    const predictButton = document.getElementById('predictButton');
    const resultElement = document.getElementById('result');

    // --- Model ---
    let model;

    // --- 1. Image Preprocessing Function ---
    function preprocessImage(imgElement) {
        // Preprocessing for MobileNetV2: resize to 224x224, 
        // normalize pixels from 0-255 to 0-1.
        return tf.tidy(() => {
            const tensor = tf.browser.fromPixels(imgElement)
                .resizeNearestNeighbor([224, 224])
                .toFloat()
                .div(tf.scalar(255.0)) // Normalize 0-1
                .expandDims();
            return tensor;
        });
    }

  // --- 2. Prediction Function ---
async function predictImage() {
    if (!model) {
        status.innerText = 'Error: Model is not loaded yet.';
        return;
    }
    if (!uploadedImage.src || uploadedImage.src.endsWith('#')) {
        status.innerText = 'Error: Please upload an image first.';
        return;
    }

    status.innerText = 'Processing and predicting...';

    const tensor = preprocessImage(uploadedImage);

    // Run prediction to get raw logits
    const logits = model.predict(tensor);

    // Apply softmax to convert logits to probabilities
    const probabilities = tf.softmax(logits);

    // Get the probability data
    const data = await probabilities.data();

    // Find the index with the highest probability
    const highestProbIndex = data.indexOf(Math.max(...data));
    const confidence = data[highestProbIndex]; // This is now 0-1

    // Display the correct result
    resultElement.innerText = `Result: ImageNet Class ID ${highestProbIndex}
Confidence: ${(confidence * 100).toFixed(2)}%`;

    status.innerText = 'Prediction complete.';
    
    // Clean up all tensors
    tensor.dispose();
    logits.dispose();
    probabilities.dispose();
}
// --- 3. Event Listeners ---
imageUpload.addEventListener('change', event => {
    const file = event.target.files[0];
    if (file) {
        const reader = new FileReader();
        reader.onload = e => {
            uploadedImage.src = e.target.result;
            uploadedImage.style.display = 'block';
            status.innerText = 'Image loaded. Click "Predict".';
            resultElement.innerText = 'Result:'; // Clear previous result
        };
        reader.readAsDataURL(file);
    }
});
...
```

**With this:**
```javascript
...
// --- 2. Prediction Function ---
async function predictImage() {
    if (!model) {
        status.innerText = 'Error: Model is not loaded yet.';
        return;
    }
    if (!uploadedImage.src || uploadedImage.src.endsWith('#')) {
        status.innerText = 'Error: Please upload an image first.';
        return;
    }

    status.innerText = 'Processing and predicting...';
    
    const tensor = preprocessImage(uploadedImage);
    
    // Run prediction to get raw logits
    const logits = model.predict(tensor);
    
    // Apply softmax to convert logits to probabilities
    const probabilities = tf.softmax(logits);
    
    // Get the probability data
    const data = await probabilities.data();
    
    // Find the index with the highest probability
    const highestProbIndex = data.indexOf(Math.max(...data));
    const confidence = data[highestProbIndex]; // This is now 0-1
    
    // Display the correct result
    resultElement.innerText = `Result: ImageNet Class ID ${highestProbIndex}
Confidence: ${(confidence * 100).toFixed(2)}%`;

    status.innerText = 'Prediction complete.';
    
    // Clean up all tensors
    tensor.dispose();
    logits.dispose();
    probabilities.dispose();
}

// --- 3. Event Listeners ---
imageUpload.addEventListener('change', event => {
    const file = event.target.files[0];
    if (file) {
        const reader = new FileReader();
        reader.onload = e => {
            uploadedImage.src = e.target.result;
            // Make the image visible
            uploadedImage.style.display = 'block'; 
            status.innerText = 'Image loaded. Click "Predict".';
            resultElement.innerText = 'Result:'; // Clear previous result
        };
        reader.readAsDataURL(file);
    }
});
    
    predictButton.addEventListener('click', predictImage);

    // --- 4. Model Loading Function ---
    async function loadModel() {
        try {
            // This is a standard, pre-hosted MobileNetV2 model
            const modelURL = 'https://tfhub.dev/google/tfjs-model/imagenet/mobilenet_v2_100_224/classification/3/default/1';
            
            console.log('Attempting to load model from:', modelURL);
            // Use loadGraphModel for TF Hub models
            model = await tf.loadGraphModel(modelURL, {fromTFHub: true}); 
            
            console.log('Model Loaded Successfully');
            status.innerText = 'MobileNetV2 Loaded. Please upload an image.';
            
        } catch (error) {
            console.error('Error loading model:', error);
            status.innerText = 'Error loading model. See console (F12).';
        }
    }
    
    // Run the model loader on page load
    loadModel();
</script>
</body>
</html>
