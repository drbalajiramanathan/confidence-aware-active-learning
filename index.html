<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>TF.js Model Loader</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
</head>
<body>
    <h1>TF.js Model Loader</h1>
    
    <input type="file" id="imageUpload" accept="image/*">
    <br>
    
    <img id="uploadedImage" alt="Upload preview" style="width: 224px; height: 224px; margin-top: 10px; border: 1px solid #ccc; display: none;">
    
    <br>
    <button id="predictButton" style="margin-top: 10px; font-size: 16px;">Predict</button>
    <p id="result" style="font-weight: bold; font-size: 18px; margin-top: 10px;">Result:</p>
    
    <p id="status">Loading model...</p>
    

    <script>
        // --- HTML Elements ---
        const status = document.getElementById('status');
        const imageUpload = document.getElementById('imageUpload');
        const uploadedImage = document.getElementById('uploadedImage');
        const predictButton = document.getElementById('predictButton');
        const resultElement = document.getElementById('result');

        // --- Model ---
        let model;

        // --- 1. Image Preprocessing Function ---
        function preprocessImage(imgElement) {
            // Preprocessing for MobileNet: resize to 224x224,
            // normalize pixels from 0-255 to 0-1.
            return tf.tidy(() => {
                const tensor = tf.browser.fromPixels(imgElement)
                    .resizeNearestNeighbor([224, 224])
                    .toFloat()
                    .div(tf.scalar(255.0))
                    .expandDims();
                return tensor;
            });
        }

        // --- 2. Prediction Function (Fix 2: With tf.softmax) ---
        async function predictImage() {
            if (!model) {
                status.innerText = 'Error: Model is not loaded yet.';
                return;
            }
            if (!uploadedImage.src || uploadedImage.src.endsWith('#')) {
                status.innerText = 'Error: Please upload an image first.';
                return;
            }

            status.innerText = 'Processing and predicting...';
            
            const tensor = preprocessImage(uploadedImage);
            
            // Run prediction to get raw logits
            const logits = model.predict(tensor);
            
            // Apply softmax to convert logits to probabilities
            const probabilities = tf.softmax(logits);
            
            // Get the probability data
            const data = await probabilities.data();
            
            // Find the index with the highest probability
            const highestProbIndex = data.indexOf(Math.max(...data));
            const confidence = data[highestProbIndex]; // This is now 0-1
            
            // Display the correct result
            resultElement.innerText = `Result: ImageNet Class ID ${highestProbIndex}
Confidence: ${(confidence * 100).toFixed(2)}%`;
            
            status.innerText = 'Prediction complete.';
            
            // Clean up all tensors
            tensor.dispose();
            logits.dispose();
            probabilities.dispose();
        }

        // --- 3. Event Listeners (Fix 3: Show image on load) ---
        imageUpload.addEventListener('change', event => {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = e => {
                    uploadedImage.src = e.target.result;
                    // Make the image visible
                    uploadedImage.style.display = 'block'; 
                    status.innerText = 'Image loaded. Click "Predict".';
                    resultElement.innerText = 'Result:'; // Clear previous result
                };
                reader.readAsDataURL(file);
            }
        });
        
        predictButton.addEventListener('click', predictImage);

        // --- 4. Model Loading Function (Fix 4: Stable Model URL) ---
        async function loadModel() {
            try {
                // This is a direct URL to a MobileNetV1 model
                const modelURL = 'https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json';
                
                console.log('Attempting to load model from:', modelURL);
                // Use loadLayersModel for this type of model
                model = await tf.loadLayersModel(modelURL); 
                
                console.log('Model Loaded Successfully');
                status.innerText = 'MobileNetV1 Loaded. Please upload an image.';
                
            } catch (error) {
                console.error('Error loading model:', error);
                status.innerText = 'Error loading model. See console (F12).';
            }
        }
        
        // Run the model loader on page load
        loadModel();
    </script>
</body>
</html>
